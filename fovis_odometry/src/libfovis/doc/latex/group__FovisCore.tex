\hypertarget{group__FovisCore}{
\section{Fovis core}
\label{group__FovisCore}\index{Fovis core@{Fovis core}}
}


Core data structures and algorithms.  


\subsection*{Classes}
\begin{DoxyCompactItemize}
\item 
struct \hyperlink{structfovis_1_1CameraIntrinsicsParameters}{CameraIntrinsicsParameters}
\begin{DoxyCompactList}\small\item\em Intrinsic parameters for a pinhole camera with plumb-\/bob distortion model. \end{DoxyCompactList}\item 
class \hyperlink{classfovis_1_1DepthSource}{DepthSource}
\begin{DoxyCompactList}\small\item\em Provides depth estimates for input image pixels. \end{DoxyCompactList}\item 
class \hyperlink{classfovis_1_1FeatureMatch}{FeatureMatch}
\begin{DoxyCompactList}\small\item\em Represents a single image feature matched between two camera images taken at different times. \end{DoxyCompactList}\item 
class \hyperlink{classfovis_1_1IntensityDescriptorExtractor}{IntensityDescriptorExtractor}
\begin{DoxyCompactList}\small\item\em Extracts mean-\/normalized intensity patch around a pixel. \end{DoxyCompactList}\item 
class \hyperlink{classfovis_1_1KeypointData}{KeypointData}
\begin{DoxyCompactList}\small\item\em Image feature used for motion estimation. \end{DoxyCompactList}\item 
class \hyperlink{classfovis_1_1MotionEstimator}{MotionEstimator}
\begin{DoxyCompactList}\small\item\em Does the heavy lifting for frame-\/to-\/frame motion estimation. \end{DoxyCompactList}\item 
class \hyperlink{classfovis_1_1OdometryFrame}{OdometryFrame}
\begin{DoxyCompactList}\small\item\em Stores data specific to an input frame. \end{DoxyCompactList}\item 
class \hyperlink{classfovis_1_1PyramidLevel}{PyramidLevel}
\begin{DoxyCompactList}\small\item\em One level of a Gaussian image pyramid. \end{DoxyCompactList}\item 
class \hyperlink{classfovis_1_1Rectification}{Rectification}
\begin{DoxyCompactList}\small\item\em Maps image coordinates from an input image to image coordinates on a rectified camera. \end{DoxyCompactList}\item 
class \hyperlink{classfovis_1_1VisualOdometry}{VisualOdometry}
\begin{DoxyCompactList}\small\item\em Main visual odometry class. \end{DoxyCompactList}\end{DoxyCompactItemize}
\subsection*{Typedefs}
\begin{DoxyCompactItemize}
\item 
typedef std::map$<$ std::string, std::string $>$ \hyperlink{group__FovisCore_ga113578b67d3e37bc78f1fffd8440e1ff}{VisualOdometryOptions}
\begin{DoxyCompactList}\small\item\em Options. \end{DoxyCompactList}\end{DoxyCompactItemize}


\subsection{Detailed Description}
Core data structures and algorithms. 

\subsection{Typedef Documentation}
\hypertarget{group__FovisCore_ga113578b67d3e37bc78f1fffd8440e1ff}{
\index{Fovis core@{Fovis core}!VisualOdometryOptions@{VisualOdometryOptions}}
\index{VisualOdometryOptions@{VisualOdometryOptions}!Fovis core@{Fovis core}}
\subsubsection[{VisualOdometryOptions}]{\setlength{\rightskip}{0pt plus 5cm}VisualOdometryOptions}}
\label{group__FovisCore_ga113578b67d3e37bc78f1fffd8440e1ff}


Options. 

VisualOdometryOptions is a key-\/value dictionary of user-\/adjustable options that affect the behavior of the visual odometry algorithm. Keys and values are both expressed as strings

Current options are: \begin{DoxyVerb}
 *   "feature-window-size"
 *     Type:        Integer
 *     Default:     9
 *     Range:       1+
 *     Description: The size of the n x n image patch surrounding each feature, used for
 *                  keypoint matching.
 *      
 *   "max-pyramid-level"
 *     Type:        Integer
 *     Default:     3
 *     Range:       1+
 *     Description: The maximum Gaussian pyramid level to process the image at.
 *                  Pyramid level 1 corresponds to the original image.
 *
 *   "inlier-max-reprojection-error"
 *     Type:        Double
 *     Default:     1.5
 *     Range:       0+
 *     Description: The maximum image-space reprojection error (in pixels) a
 *                  feature match is allowed to have and still be considered an
 *                  inlier in the set of features used for motion estimation.
 *
 *   "clique-inlier-threshold"
 *     Type:        Double
 *     Default:     0.1
 *     Range:       0+
 *     Description: See Howard's greedy max-clique algorithm for determining the 
 *                  maximum set of mutually consisten feature matches.  This
 *                  specifies the compatibility threshold, in meters.
 *
 *   "min-features-for-estimate"
 *     Type:        Integer
 *     Default:     10
 *     Range:       0+
 *     Description: Minimum number of features in the inlier set for the motion estimate
 *     to be considered valid.
 *
 *   "max-mean-reprojection-error"
 *     Type:        Double
 *     Default:     10.0
 *     Range:       0+
 *     Description: Maximum mean reprojection error over the inlier feature matches for the
 *     motion estimate to be considered valid.
 *
 *   "use-subpixel-refinement"
 *     Type:        Integer
 *     Default:     1
 *     Range:       0 or 1
 *     Description: Specifies whether or not to refine feature matches to
 *     subpixel resolution.
 *
 *   "feature-search-window"
 *     Type:        Integer
 *     Default:     25
 *     Range:       0+
 *     Description: Specifies the size of the search window to apply when
 *     searching for feature matches across time frames.  The search is conducted
 *     around the feature location predicted by the initial rotation estimate.
 *
 *   "target-pixels-per-feature"
 *     Type:        Integer
 *     Default:     250
 *     Range:       1+
 *     Description: Specifies the desired feature density as a ratio of input
 *                  image pixels per feature detected.  This number is used to control
 *                  the adaptive feature thresholding.
 *
 *   "update-target-features-with-refined"
 *     Type:        Integer
 *     Default:     0
 *     Range:       0 or 1
 *     Description: When subpixel refinement is enabled, the refined feature
 *                  locations can be saved over the original feature
 *                  locations.  This has a slightly negative impact on
 *                  frame-to-frame visual odometry, but is likely better when
 *                  using this library as part of a visual SLAM
 *                  algorithm.
 * \end{DoxyVerb}
 